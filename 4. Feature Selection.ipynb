{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1022, 1853)"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from usfull_tools import load_DS\n",
    "from catboost import Pool, CatBoostRegressor, CatBoostClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "pd.options.display.max_columns = None\n",
    "%matplotlib inline\n",
    "\n",
    "from set_vars import KAGGLE_PREFIX, debug_mode, KAGGLE_DIR, target_column, target_type, loss_function, custom_metric\n",
    "\n",
    "train, test = load_DS(debug_mode, KAGGLE_DIR, KAGGLE_PREFIX, '_prepare.csv')\n",
    "del test\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(train[train.columns.drop(target_column)], train[target_column], \n",
    "                                                    test_size=0.3, random_state=42)\n",
    "X_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Column prefixes:\n",
    "-  _nan__median, _nan__min, _nan__max, _nan__0 - nan replaced by median\n",
    "-  _idxmax - nan replaced by most frequent\n",
    "-  _isnull - is null flag\n",
    "-  _dummie - dumnie for categorical column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iterations : 103.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: Custom metrics will not be evaluated because there are no test datasets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 180439.5976178\ttotal: 1m 42s\tremaining: 2h 54m 51s\n",
      "1:\tlearn: 165536.1864331\ttotal: 3m 25s\tremaining: 2h 52m 32s\n",
      "2:\tlearn: 152182.0767863\ttotal: 5m 4s\tremaining: 2h 49m 17s\n",
      "3:\tlearn: 139274.7457142\ttotal: 5m 17s\tremaining: 2h 10m 48s\n",
      "4:\tlearn: 127661.1173537\ttotal: 5m 29s\tremaining: 1h 47m 32s\n",
      "5:\tlearn: 117464.7138453\ttotal: 7m 15s\tremaining: 1h 57m 17s\n",
      "6:\tlearn: 108236.9276810\ttotal: 9m 14s\tremaining: 2h 6m 47s\n",
      "7:\tlearn: 100288.4996062\ttotal: 11m 12s\tremaining: 2h 13m\n",
      "8:\tlearn: 92426.0671813\ttotal: 11m 15s\tremaining: 1h 57m 33s\n",
      "9:\tlearn: 85589.4288257\ttotal: 11m 28s\tremaining: 1h 46m 46s\n",
      "10:\tlearn: 79987.3159165\ttotal: 13m 36s\tremaining: 1h 53m 48s\n"
     ]
    }
   ],
   "source": [
    "iterations = np.round(10 + len(X_train.columns)/20)\n",
    "print('iterations :', iterations)\n",
    "\n",
    "if target_type=='binary':\n",
    "    loss_function='CrossEntropy'\n",
    "    custom_metric='Accuracy'\n",
    "    model = CatBoostClassifier(random_seed = 42, iterations=iterations, depth=2, learning_rate=0.1, \n",
    "                               loss_function=loss_function, custom_metric=loss_function, od_type = 'Iter')\n",
    "elif target_type=='interval':\n",
    "    loss_function='RMSE'\n",
    "    custom_metric='RMSE'\n",
    "    model = CatBoostRegressor(random_seed = 42, iterations=iterations, depth=12, learning_rate=0.1, \n",
    "                              loss_function=loss_function, custom_metric=loss_function, od_type = 'Iter')\n",
    "    \n",
    "#https://tech.yandex.com/catboost/doc/dg/concepts/python-reference_parameters-list-docpage/#python-reference_parameters-list\n",
    "\n",
    "# Для CatBoost требуется явно указывать категориальные переменные\n",
    "i=0\n",
    "cat_features = []\n",
    "for column in X_train.columns:\n",
    "    if X_train[column].dtype == 'object': cat_features.append(i)\n",
    "    i +=1\n",
    "\n",
    "model.fit(X_train, y_train, cat_features)\n",
    "\n",
    "from sklearn.metrics import mean_absolute_error, accuracy_score\n",
    "\n",
    "if custom_metric=='Accuracy':\n",
    "    print(\"Accuracy: %.3f\"\n",
    "          % accuracy_score(model.predict(X_test), y_test))\n",
    "\n",
    "if custom_metric=='RMSE':\n",
    "    print(\"RMSE: %.3f\"\n",
    "          % mean_absolute_error(model.predict(X_test), y_test))\n",
    "\n",
    "\n",
    "feature_importance = pd.DataFrame(list(zip(X_test.dtypes.index, \n",
    "                                           model.get_feature_importance(Pool(X_test, label=y_test, cat_features=cat_features)))),\n",
    "                                    columns=['Feature','Score'])\n",
    "\n",
    "feature_importance = feature_importance.sort_values(by='Score', ascending=False, inplace=False, kind='quicksort', na_position='last')\n",
    "\n",
    "#TO DO: сделать отбор лучшего из нескольких корелирующих параметров"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Keep features with > 1% normalize importance\n",
    "fi = feature_importance[feature_importance.Score > 1]\n",
    "print(len(X_train.columns), '->', len(fi.index), 'non zero important features:', np.round(fi.Score.sum(),1), '%')\n",
    "fi.sort_values('Score', ascending = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fi.to_csv(KAGGLE_DIR + KAGGLE_PREFIX + '_important_columns.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
